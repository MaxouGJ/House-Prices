{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dataInput(fileName):\n",
    "    #Chargemment des données\n",
    "    dataL= []\n",
    "    f = open(fileName,\"rb\")\n",
    "    readerT = csv.reader(f, delimiter=',', dialect='excel')\n",
    "    for row in readerT:\n",
    "        dataL.append(row)\n",
    "    f.close()\n",
    "    headings = []\n",
    "    headings.append(dataL.pop(0)) #removing column heads\n",
    "    dataA = np.array(dataL)\n",
    "    #print ' dataA.ndim = ',dataA.ndim,' dataA.shape = ',dataA.shape,' dataA.size = ',dataA.size\n",
    "    #print 'dataA.dtype = ',dataA.dtype,' dataA.itemsize = ',dataA.itemsize \n",
    "    return dataA, headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prix vs surface totale (colonnes 38 (sous-sol) & 46 (surface habitée) ) et condition de vente (colonne 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PriceSurface(dataA):\n",
    "    #\n",
    "    x1L = []\n",
    "    y1L = []\n",
    "    x2L = []\n",
    "    y2L = []\n",
    "    x3L = []\n",
    "    y3L = []\n",
    "    x4L = []\n",
    "    y4L = []\n",
    "    x5L = []\n",
    "    y5L = []\n",
    "    x6L = []\n",
    "    y6L = []\n",
    "    #Condition de vente\n",
    "    for i in range(dataA.shape[0]):\n",
    "        if dataA[i,79] == 'Normal':\n",
    "            x1L.append(float(dataA[i,38]) + float(dataA[i,46]))\n",
    "            y1L.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Abnorml':\n",
    "            x2L.append(float(dataA[i,38]) + float(dataA[i,46]))\n",
    "            y2L.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'AdjLand':\n",
    "            x3L.append(float(dataA[i,38]) + float(dataA[i,46]))\n",
    "            y3L.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Alloca':\n",
    "            x4L.append(float(dataA[i,38]) + float(dataA[i,46]))\n",
    "            y4L.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Family':\n",
    "            x5L.append(float(dataA[i,38]) + float(dataA[i,46]))\n",
    "            y5L.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Partial':\n",
    "                x6L.append(float(dataA[i,38]) + float(dataA[i,46]))\n",
    "                y6L.append(dataA[i,-1])  \n",
    "    x1 = np.array(x1L,dtype = 'f')\n",
    "    y1 = np.array(y1L,dtype = 'f')\n",
    "    x2 = np.array(x2L,dtype = 'f')\n",
    "    y2 = np.array(y2L,dtype = 'f')\n",
    "    x3 = np.array(x3L,dtype = 'f')\n",
    "    y3 = np.array(y3L,dtype = 'f')\n",
    "    x4 = np.array(x4L,dtype = 'f')\n",
    "    y4 = np.array(y4L,dtype = 'f')\n",
    "    x5 = np.array(x5L,dtype = 'f')\n",
    "    y5 = np.array(y5L,dtype = 'f')\n",
    "    x6 = np.array(x6L,dtype = 'f')\n",
    "    y6 = np.array(y6L,dtype = 'f')\n",
    "    print ' corMat for Normal contracts only and all areas vs price = '\n",
    "    print np.corrcoef(x1,y1,rowvar=0)\n",
    "    print ' corMat for Abnorml contracts only and all areas vs price = '\n",
    "    print np.corrcoef(x2,y2,rowvar=0)\n",
    "    print ' corMat for Partial contracts only and all areas vs price = '\n",
    "    print np.corrcoef(x6,y6,rowvar=0)\n",
    "    x1Le = len(x1L)\n",
    "    x2Le = len(x2L)\n",
    "    x3Le = len(x3L)\n",
    "    x4Le = len(x4L)\n",
    "    x5Le = len(x5L)\n",
    "    x6Le = len(x6L)\n",
    "    label1 = 'Normal'+ ' '+ str(x1Le) + ' '+str(int(100.*x1Le/len(dataA[:,80])))+'%'\n",
    "    label2 = 'Abnorml' + ' '+ str(x2Le) + ' '+str(int(100.*x2Le/len(dataA[:,80])))+'%'\n",
    "    label3 = 'AdjLand' + ' '+ str(x3Le) + ' '+str(int(100.*x3Le/len(dataA[:,80])))+'%'\n",
    "    label4 = 'Alloca' + ' '+ str(x4Le) + ' '+str(int(100.*x4Le/len(dataA[:,80])))+'%'\n",
    "    label5 = 'Family' + ' '+ str(x5Le) + ' '+str(int(100.*x5Le/len(dataA[:,80])))+'%'\n",
    "    label6 = 'Partial' + ' '+ str(x6Le) + ' '+str(int(100.*x6Le/len(dataA[:,80])))+'%'\n",
    "\n",
    "    fig = plt.figure(figsize(12,9), dpi = 80)\n",
    "    plt.xlim(0,8000)\n",
    "    plt.ylim(0,800000)\n",
    "    plt.title('PRICE vs TOTAL FOOTAGE')\n",
    "    plt.xlabel('SQ FT')\n",
    "    plt.ylabel('PRICE')\n",
    "     #scatter(x1,y1,c='r',s=200,alpha=0.5,label = 'Normal')\n",
    "    scatter(x1,y1,c='r',s=200,alpha=0.5,label = label1)\n",
    "    scatter(x2,y2,c='b',s=200,alpha=0.5,label = label2)\n",
    "    scatter(x3,y3,c='g',s=200,alpha=0.5, label = label3)\n",
    "    scatter(x4,y4,c='y',s=200,alpha=0.5, label = label4)\n",
    "    scatter(x5,y5,c='c',s=200,alpha=0.5, label = label5)\n",
    "    scatter(x6,y6,c='k',s=200,alpha=0.5, label = label6)\n",
    "    plt.legend(loc='upper left',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification d'exemples outliers (surface totale trop élevée vs prix): lignes 1498, 2180 & 2181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def outliers(dataA):\n",
    "    for j in range(len(dataA[:,36])):\n",
    "        if float(dataA[j,38]) + float(dataA[j,46]) > 7500:\n",
    "            print ' example (j+1) ', j+1,' is outlier',' since area = ',\n",
    "            print float(dataA[j,38]) + float(dataA[j,46]),' and price = ',dataA[j,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corMat(x1,y1):\n",
    "    return np.corrcoef(x1,y1,rowvar=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul de corrélations prix vs surface pour surface totale (c38+c46) et surfaces composantes (c38 (sous-sol) & c46 (habitée))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PriceSurfaceCalculations(dataA):        \n",
    "    PriceSurface(dataA)\n",
    "    price = np.array(dataA[:,-1],dtype = 'f')\n",
    "    surfaceL = []\n",
    "    for i in range(len(dataA[:,36])):\n",
    "        surfaceL.append((dataA[i,38]+dataA[i,46]))\n",
    "    surfaceT = np.array(surfaceL,dtype = 'f')\n",
    "    surfaceB = np.array(dataA[:,38],dtype = 'f')\n",
    "    surfaceGLA = np.array(dataA[:,46],dtype = 'f')\n",
    "    print ' corMat for all contracts and all areas vs price = '\n",
    "    print corMat(surfaceT,price)\n",
    "    print ' corMat for all and Basement area vs price = '\n",
    "    print corMat(surfaceB,price)\n",
    "    print ' corMat for all and Gr living area vs price= '\n",
    "    print corMat(surfaceGLA,price)\n",
    "    return 'ok'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrélation entre surface totale (C38 + C46) vs prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def case2_sum2surfaces(dataA,colDigitPrice,model,alpha):\n",
    "    #ARRAY OF INPUTS\n",
    "    totalSurface = np.zeros((dataA.shape[0],1),dtype='f')\n",
    "    for i in range(dataA.shape[0]):\n",
    "        totalSurface[i][0] = float(dataA[i,38])+float(dataA[i,46])\n",
    "    clf = LR_models(model,totalSurface,colDigitPrice,alpha)\n",
    "    print totalSurface.shape, colDigitPrice.shape\n",
    "    print ' Case 2: sum of 2 surfaces with LR model = ',model,' and alpha = ',alpha\n",
    "    print 'clf.coef =',clf.coef_,' clf.coef_.shape = ',clf.coef_.shape\n",
    "    #print 'clf.get_params() = ',clf.get_params()#inutile\n",
    "    #print 'clf.intercept = ',clf.intercept_\n",
    "    #print 'clf.score(X,y) R^2 = ',clf.score(totalSurface,colDigitPrice)\n",
    "    if model == 'RidgeCV':\n",
    "        print 'clf.alpha estimated = ',clf.alpha_\n",
    "    predictedY = clf.predict(totalSurface)\n",
    "    error = 0\n",
    "    for i in range(dataA.shape[0]):   \n",
    "        error += np.abs(colDigitPrice[i]-predictedY[i])/colDigitPrice[i]\n",
    "    errorA = 100*error/dataA.shape[0]\n",
    "    print ' error at training = ', errorA\n",
    "    return errorA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des colonnes numériques version sans col 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colDigitN(dataA):\n",
    "    colDigit = []\n",
    "    for i in range(dataA.shape[1]):\n",
    "        if str(dataA[0,i]).isdigit():\n",
    "            colDigit.append(i)\n",
    "    colDigit.pop(0)\n",
    "    colDigit.remove(3) #too many no digit\n",
    "    colDigit.remove(26) #too many no digit\n",
    "    colDigit.remove(59) #too many no digit\n",
    "    return colDigit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification des colonnes numériques version avec col 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def colDigitFn(dataA):\n",
    "    colDigit = []\n",
    "    for i in range(dataA.shape[1]):\n",
    "        if str(dataA[0,i]).isdigit():\n",
    "            colDigit.append(i)\n",
    "    #print 'len(colDigit) = ',len(colDigit)\n",
    "    #print colDigit\n",
    "    colDigit.pop(0)\n",
    "    colDigit.remove(3) #too many no digit\n",
    "    colDigit.remove(26) #too many no digit\n",
    "    colDigit.remove(59) #too many no digit\n",
    "    colDigit.insert(2,12) # + new col 12 modifiée\n",
    "    return colDigit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du tableau contenant les données des colonnes numériques version sans col 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corMatDS(colDigit,dataA):\n",
    "    colDigitArray = arange(len(colDigit)*dataA.shape[0],dtype='f').reshape(dataA.shape[0],len(colDigit))\n",
    "    nodig = 0\n",
    "    for j in range(dataA.shape[0]):\n",
    "        ii = 0                                                               \n",
    "        for i in colDigit:\n",
    "            if not str(dataA[j,i]).isdigit():\n",
    "                colDigitArray[j,ii] = 0.  #for 332,47 & 332,48\n",
    "                nodig += 1\n",
    "                ii += 1                \n",
    "            else:\n",
    "                colDigitArray[j,ii] = float(dataA[j,i])\n",
    "                ii += 1\n",
    "    if nodig != 0:\n",
    "        print 'nodig = ',nodig\n",
    "    np.savetxt(\"colDigitArray.csv\", colDigitArray, delimiter=\",\",fmt = '%s')\n",
    "    return colDigitArray "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du tableau contenant les données des colonnes numériques version avec col 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def digitArrayPlus12Fn(colDigit,dataA,coL12):\n",
    "    colDigitArray = arange((len(colDigit)-1)*dataA.shape[0],dtype='f').reshape(dataA.shape[0],(len(colDigit)-1))\n",
    "    #print 'len(colDigit) = ',len(colDigit)\n",
    "    nodig = 0\n",
    "    #print 'colDigit = ',colDigit\n",
    "    #INSERT 12 AT POSITION 2 THEN AT I = 12 coldigitarray = coL12[j]\n",
    "    for j in range(dataA.shape[0]):\n",
    "        ii = 0 \n",
    "        for i in colDigit:                                                           \n",
    "            if i != 12 and not str(dataA[j,i]).isdigit():\n",
    "                colDigitArray[j,ii] = 0.  #for 332,47 & 332,48\n",
    "                nodig += 1\n",
    "                ii += 1\n",
    "            else:\n",
    "                if i == 12 :\n",
    "                    colDigitArray[j,ii] = float(coL12[j])\n",
    "                    ii += 1\n",
    "                else:\n",
    "                    if i == 80 : #removing price\n",
    "                        pass\n",
    "                    else:\n",
    "                        colDigitArray[j,ii] = float(dataA[j,i])\n",
    "                        ii += 1\n",
    "    #if nodig != 0:\n",
    "        #print 'À corMatDSPlus12 nodig = ',nodig,' remplacé par 0.'\n",
    "    return colDigitArray "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de corrélation sur les conditions de vente (colonne 79) par fréquence vs prix: \n",
    "Résultats: corrélation linéaire basse: 0.0088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def col79(dataA):\n",
    "    arr79 = colDigitArray = arange(dataA.shape[0],dtype='f').reshape(dataA.shape[0],1)\n",
    "    priceNL = []\n",
    "    priceAbL = []\n",
    "    priceAdL = []\n",
    "    priceAlL = []\n",
    "    priceFL = []\n",
    "    pricePL = []\n",
    "    for i in range(dataA.shape[0]):\n",
    "        if dataA[i,79] == 'Normal':\n",
    "            #arr79[i] = 6\n",
    "            priceNL.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Abnorml':\n",
    "            #arr79[i] = 4\n",
    "            priceAbL.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'AdjLand':\n",
    "            #arr79[i] = 1\n",
    "            priceAdL.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Alloca':\n",
    "            #arr79[i] = 2\n",
    "            priceAlL.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Family':\n",
    "            #arr79[i] = 3\n",
    "            priceFL.append(dataA[i,-1])\n",
    "        elif dataA[i,79] == 'Partial':\n",
    "            #arr79[i] = 5\n",
    "            pricePL.append(dataA[i,-1])\n",
    "    #Classement par fréquence\n",
    "    for i in range(dataA.shape[0]):\n",
    "        if dataA[i,79] == 'Normal':\n",
    "            arr79[i] = float(len(priceNL))/float(dataA.shape[0])\n",
    "        elif dataA[i,79] == 'Abnorml':\n",
    "            arr79[i] = float(len(priceAbL))/float(dataA.shape[0])\n",
    "        elif dataA[i,79] == 'AdjLand':\n",
    "            arr79[i] = float(len(priceAdL))/float(dataA.shape[0])\n",
    "        elif dataA[i,79] == 'Alloca':\n",
    "            arr79[i] = float(len(priceAlL))/float(dataA.shape[0])\n",
    "        elif dataA[i,79] == 'Family':\n",
    "            arr79[i] = float(len(priceFL))/float(dataA.shape[0])\n",
    "        elif dataA[i,79] == 'Partial':\n",
    "            arr79[i] = float(len(pricePL))/float(dataA.shape[0])\n",
    "    priceN = np.array(priceNL,dtype = float).reshape(len(priceNL))\n",
    "    priceAb = np.array(priceAbL,dtype = float).reshape(len(priceAbL))\n",
    "    priceAd = np.asarray(priceAdL,dtype = float).reshape(len(priceAdL))\n",
    "    priceAl = np.asarray(priceAlL,dtype = float).reshape(len(priceAlL))\n",
    "    priceF = np.asarray(priceFL,dtype = float).reshape(len(priceFL))\n",
    "    priceP = np.asarray(pricePL,dtype = float).reshape(len(pricePL))\n",
    "    print  'priceN.size = ',priceN.size,' priceN.mean() = ',priceN.mean(),' priceN.std() = ',priceN.std(),'Var/mean = ',priceN.std()/priceN.mean()\n",
    "    print  'priceAb.size = ',priceAb.size,' priceAb.mean() = ',priceAb.mean(),' priceAb.std() = ',priceAb.std(),'Var/mean = ',priceAb.std()/priceAb.mean()\n",
    "    print  'priceAd.size = ',priceAd.size,' priceAd.mean() = ',priceAd.mean(),' priceAd.std() = ',priceAd.std(),'Var/mean = ',priceAd.std()/priceAd.mean()\n",
    "    print  'priceAl.size = ',priceAl.size,' priceAl.mean() = ',priceAl.mean(),' priceAl.std() = ',priceAl.std(),'Var/mean = ',priceAl.std()/priceAl.mean()\n",
    "    print  'priceF.size = ',priceF.size,' priceF.mean() = ',priceF.mean(),' priceF.std() = ',priceF.std(),'Var/mean = ',priceF.std()/priceF.mean()\n",
    "    print  'priceP.size = ',priceP.size,' priceP.mean() = ',priceP.mean(),' priceP.std() = ',priceP.std(),'Var/mean = ',priceP.std()/priceP.mean()\n",
    "    return arr79"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de corrélation sur la localisation par zone (colonne 2) par fréquence: \n",
    "Résultats: corrélation linéaire = 0.28 non ajoutée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def col2(dataA):\n",
    "    arr2 = colDigitArray = arange(dataA.shape[0],dtype='f').reshape(dataA.shape[0],1)\n",
    "    MSZaL = []\n",
    "    MSZcL = []\n",
    "    MSZfvL = []\n",
    "    MSZiL = []\n",
    "    MSZrhL = []\n",
    "    MSZrlL = []\n",
    "    MSZrpL = []\n",
    "    MSZrmL = []\n",
    "    #Données par zone\n",
    "    for i in range(dataA.shape[0]):\n",
    "        if dataA[i,2] == 'A (agr)':\n",
    "            #arr2[i] = 2\n",
    "            MSZaL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'C (all)':\n",
    "            #arr2[i] = 3\n",
    "            MSZcL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'FV':\n",
    "            #arr2[i] = 8\n",
    "            MSZfvL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'I':\n",
    "            #arr2[i] = 1\n",
    "            MSZiL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'RH':\n",
    "            #arr2[i] = 4\n",
    "            MSZrhL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'RL':\n",
    "            #arr2[i] = 6\n",
    "            MSZrlL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'RP':\n",
    "            #arr2[i] = 7\n",
    "            MSZrpL.append(dataA[i,-1])\n",
    "        elif dataA[i,2] == 'RM':\n",
    "            #arr2[i] = 5\n",
    "            MSZrmL.append(dataA[i,-1])\n",
    "    #Classification par fréquence\n",
    "    for i in range(dataA.shape[0]):\n",
    "        if dataA[i,2] == 'A (agr)':\n",
    "            arr2[i] = float(len(MSZaL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'C (all)':\n",
    "            arr2[i] = float(len(MSZcL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'FV':\n",
    "            arr2[i] = float(len(MSZfvL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'I':\n",
    "            arr2[i] = float(len(MSZiL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'RH':\n",
    "            arr2[i] = float(len(MSZrhL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'RL':\n",
    "            arr2[i] = float(len(MSZrlL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'RP':\n",
    "            arr2[i] = float(len(MSZrpL))/float(dataA.shape[0])\n",
    "        elif dataA[i,2] == 'RM':\n",
    "            arr2[i] = float(len(MSZrmL))/float(dataA.shape[0])\n",
    "            MSZrmL.append(dataA[i,-1])\n",
    "    sumL =  len(MSZaL)+len(MSZcL)+len(MSZfvL)+len(MSZiL)+len(MSZrhL)+len(MSZrlL)+len(MSZrpL)+len(MSZrmL)    \n",
    "    MSZa = np.array(MSZaL,dtype = float).reshape(len(MSZaL))\n",
    "    MSZc = np.array(MSZcL,dtype = float).reshape(len(MSZcL))\n",
    "    MSZfv = np.asarray(MSZfvL,dtype = float).reshape(len(MSZfvL))\n",
    "    MSZi = np.asarray(MSZiL,dtype = float).reshape(len(MSZiL))\n",
    "    MSZrh = np.asarray(MSZrhL,dtype = float).reshape(len(MSZrhL))\n",
    "    MSZrl = np.asarray(MSZrlL,dtype = float).reshape(len(MSZrlL))\n",
    "    MSZrp = np.asarray(MSZrpL,dtype = float).reshape(len(MSZrpL)) \n",
    "    MSZrm = np.asarray(MSZrmL,dtype = float).reshape(len(MSZrmL))\n",
    "    \n",
    "    print  'len(MSZaL) = ',len(MSZaL),'MSZa.size = ',MSZa.size,' MSZa.mean() = ',MSZa.mean(),' MSZa.std() = ',MSZa.std(),'std/mean = ',MSZa.std()/MSZa.mean()\n",
    "    print  'len(MSZcL) = ',len(MSZcL),'MSZc.size = ',MSZc.size,' MSZc.mean() = ',MSZc.mean(),' MSZc.std() = ',MSZc.std(),'std/mean = ',MSZc.std()/MSZc.mean()\n",
    "    print  'len(MSZfvL) = ',len(MSZfvL),'MSZfv.size = ',MSZfv.size,' MSZfv.mean() = ',MSZfv.mean(),' MSZfv.std() = ',MSZfv.std(),'std/mean = ',MSZfv.std()/MSZfv.mean()\n",
    "    print  'len(MSZiL) = ',len(MSZiL),'MSZi.size = ',MSZi.size,' MSZi.mean() = ',MSZi.mean(),' MSZi.std() = ',MSZi.std(),'std/mean = ',MSZi.std()/MSZi.mean()\n",
    "    print  'len(MSZrhL) = ',len(MSZrhL),'MSZrh.size = ',MSZrh.size,' MSZrh.mean() = ',MSZrh.mean(),' MSZrh.std() = ',MSZrh.std(),'std/mean = ',MSZrh.std()/MSZrh.mean()\n",
    "    print  'len(MSZrlL) = ',len(MSZrlL),'MSZrl.size = ',MSZrl.size,' MSZrl.mean() = ',MSZrl.mean(),' MSZrl.std() = ',MSZrl.std(),'std/mean = ',MSZrl.std()/MSZrl.mean()\n",
    "    print  'len(MSZrpL) = ',len(MSZrpL),'MSZrp.size = ',MSZrp.size,' MSZrp.mean() = ',MSZrp.mean(),' MSZrp.std() = ',MSZrp.std(),'std/mean = ',MSZrp.std()/MSZrp.mean()\n",
    "    print  'len(MSZrmL) = ',len(MSZrmL),'MSZrm.size = ',MSZrm.size,' MSZrm.mean() = ',MSZrm.mean(),' MSZrm.std() = ',MSZrm.std(),'std/mean = ',MSZrm.std()/MSZrm.mean()\n",
    "    print ' dataA.shape[0] = ',dataA.shape[0],' sum lists = ',sumL\n",
    "    return arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse de corrélation sur la localisation par quartier de Ames City (colonne 12) par prix moyen par quartier: \n",
    "Résultats: corrélation linéaire =  0.7 ajoutée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def col12(dataA):\n",
    "    location = ['Blmngtn','Blueste','BrDale','BrkSide','ClearCr','CollgCr','Crawfor','Edwards','Gilbert','Greens','GrnHill','IDOTRR','MeadowV','Mitchel','NAmes','NoRidge','NPkVill','NridgHt','NWAmes','OldTown','SWISU','Sawyer','SawyerW','Somerst','StoneBr','Timber','Veenker']\n",
    "    #Erreur de description des données; à ajouter: 'Greens' & 'GrnHill' et correction 'ClearCr'\n",
    "    count = np.zeros(len(location), dtype=float)\n",
    "    price = np.zeros(len(location), dtype=float)\n",
    "    #Classement des données selon le quatier\n",
    "    for i in range(dataA.shape[0]):\n",
    "        for j in range(len(location)):\n",
    "            if dataA[i,12] == location[j]:\n",
    "                count[j] += 1\n",
    "                price[j] += float(dataA[i,80])\n",
    "    #Calcul du prix moyen par quartier\n",
    "    avPrice = []\n",
    "    for j in range(len(location)):\n",
    "        avPrice.append((j,price[j]/count[j]))              \n",
    "         #print ' count for ',location[j],' = {0:4.0f}'.format(count[j]),' average selling price = {:15.0f}'.format(float(avPrice[j][1]))\n",
    "    #Classement prix moyen vs quartier\n",
    "    avPrice.sort(key=itemgetter(1),reverse=True)\n",
    "     #for i in range(len(avPrice)):\n",
    "         #print location[avPrice[i][0]],count[avPrice[i][0]],avPrice[i][1]\n",
    "    ar12 = np.zeros(dataA.shape[0], dtype=float).reshape(dataA.shape[0],1)\n",
    "    #Assignation d'une cote selon la classe de prix moyen\n",
    "    for i in range(dataA.shape[0]):\n",
    "        for j in range(len(avPrice)):\n",
    "            if dataA[i,12] == location[avPrice[j][0]]:\n",
    "                ar12[i] = float(len(avPrice) - j)\n",
    "                break    \n",
    "        if ar12[i] == 0:\n",
    "            print ' ar12[',i,'] is zero'\n",
    "    return ar12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Choix et implantation de modèles linéaires de sklearn avec régulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LR_models(model,X,y,fit_intercept,alpha):\n",
    "    #fit_intercept = True #=NORMAL\n",
    "    #fit_intercept = False\n",
    "    if model == 'Ridge':\n",
    "        #lrMR = Ridge(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None,tol=0.001, solver='auto', random_state=None)\n",
    "        lrMR = Ridge(alpha,fit_intercept)\n",
    "    elif model == 'Lasso':\n",
    "        #lrMR = Lasso(alpha=1.0, fit_intercept=True, normalize=False, precompute=False,copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')\n",
    "        lrMR = Lasso(alpha,fit_intercept)\n",
    "    elif model == 'RidgeCV':\n",
    "        #lrMR = RidgeCV(alphas=(0.1, 1.0, 10.0), fit_intercept=True, normalize=False, scoring=None,cv=None, gcv_mode=None, store_cv_values=False)\n",
    "        lrMR = RidgeCV((0.1, 1.0, 10.0),fit_intercept)\n",
    "    elif model == 'ElasticNet':\n",
    "        l1_ratio=0.5\n",
    "        max_iter=1000\n",
    "        tol=0.0001\n",
    "        Precompute=False\n",
    "        fit_intercept=True\n",
    "        lrMR = ElasticNet(alpha, l1_ratio=0.5, fit_intercept=True, normalize=False,precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None,selection='cyclic')\n",
    "        #lrMR = ElasticNet(alpha, l1_ratio,fit_intercept,Precompute,max_iter,tol)\n",
    "        #lrMR = ElasticNet(alpha,fit_intercept)\n",
    "    elif model == 'LassoCV':\n",
    "        print 'AT LASSOCV with lrMR = LassoCV(eps=0.001, n_alphas=100, alphas=None, '\n",
    "        print \"fit_intercept=True, normalize=False,precompute='auto', max_iter=1000, \"\n",
    "        print 'tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=1, positive=False,'\n",
    "        print \"random_state=None, selection='cyclic')\"\n",
    "        #lrMR = LassoCV(eps=0.001, n_alphas=100, alphas=None, fit_intercept=True, normalize=False,precompute='auto', max_iter=1000, tol=0.0001, copy_X=True, cv=None, verbose=False, n_jobs=1, positive=False,random_state=None, selection='cyclic')\n",
    "        #AT ALPHA = 0, BELOW NOT WORKING\n",
    "        lrMR = LassoCV(alpha,fit_intercept)\n",
    "    elif model == 'LassoLarsCV':\n",
    "        #lrMR = LassoLarsCV(fit_intercept=True, verbose=False, max_iter=500, normalize=True,precompute='auto', cv=None, max_n_alphas=1000, n_jobs=1, eps=2.2204460492503131e-16, copy_X=True,positive=False)\n",
    "         lrMR = LassoLarsCV(fit_intercept)\n",
    "    else:\n",
    "        print 'Modèle linéaire = ',model,' non existant'\n",
    "        return 0\n",
    "    lrMR.fit(X,y)\n",
    "    return lrMR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Méthodes de sélection de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureSelectionCorCoef(arX,arY,k):\n",
    "    #Par ordre de coefficients de corrélation\n",
    "    dataM = np.insert(arX,arX.shape[1],arY,axis=1)\n",
    "    corMat = np.corrcoef(dataM.T)\n",
    "    decliningR2 = []\n",
    "    selectedFeatures = []\n",
    "    for i in range(corMat.shape[0]):\n",
    "        decliningR2.append((i,np.abs(corMat[i,-1])))\n",
    "    decliningR2.sort(key=itemgetter(1),reverse=True)\n",
    "    #orderedArrayV = arange(arX.shape[0]*colDigitArray.shape[1],dtype='f').reshape(colDigitArray.shape[0],colDigitArray.shape[1])\n",
    "    orderedArrayV = arange(arX.shape[0]*(k),dtype='f').reshape(arX.shape[0],(k))\n",
    "    #print 'colDigitArray[i,decliningR2[j+1][0]] = ',colDigitArray[i,decliningR2[1][0]]\n",
    "    for j in range(k):\n",
    "        selectedFeatures.append(decliningR2[j+1][0])\n",
    "        A = decliningR2[j+1][0]\n",
    "        for i in range(arX.shape[0]):\n",
    "            orderedArrayV[i,j] = arX[i,decliningR2[j+1][0]]\n",
    "    print 'orderedArrayV.shape = ',orderedArrayV.shape\n",
    "    #print 'selectedFeatures = ',selectedFeatures\n",
    "    return orderedArrayV,k,selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureSelection2CorCoef(arX,arY,k):\n",
    "    #Par ordre de coefficients de corrélation; inclu les graphiques \n",
    "    dataM = np.insert(arX,arX.shape[1],arY,axis=1)\n",
    "    corMat = np.corrcoef(dataM.T)\n",
    "    decliningR2 = []\n",
    "    selectedFeatures = []\n",
    "    for i in range(corMat.shape[0]):\n",
    "        decliningR2.append((i,np.abs(corMat[i,-1])))\n",
    "    decliningR2.sort(key=itemgetter(1),reverse=True)\n",
    "    print 'len(decliningR2) = ',len(decliningR2)\n",
    "    print 'arX.shape = ',arX.shape\n",
    "    #orderedArrayV = arange(arX.shape[0]*colDigitArray.shape[1],dtype='f').reshape(colDigitArray.shape[0],colDigitArray.shape[1])\n",
    "    orderedArrayV = arange(arX.shape[0]*(k),dtype='f').reshape(arX.shape[0],(k))\n",
    "    #print 'colDigitArray[i,decliningR2[j+1][0]] = ',colDigitArray[i,decliningR2[1][0]]\n",
    "    for j in range(1,k):\n",
    "        selectedFeatures.append(decliningR2[j+1][0])\n",
    "        #print 'decliningR2[j+1][0] = ',decliningR2[j+1][0]\n",
    "        for i in range(arX.shape[0]): \n",
    "            orderedArrayV[i,j] = arX[i,decliningR2[j+1][0]]\n",
    "    #print 'selectedFeatures = ',selectedFeatures\n",
    "    label1 = 'R**2'\n",
    "    label2 = 'Variable ID'\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(decliningR2)):\n",
    "        x.append(decliningR2[i][0])\n",
    "        y.append(decliningR2[i][1])\n",
    "    fig1 = plt.figure(figsize(6,3), dpi = 80)\n",
    "    plt.xlim(0,len(x))\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.title('R2 vs Variable ID: FOR DEG 2 TRANSFO OF SELECTED 9 best features =  [34, 3, 2, 14, 10, 23, 24, 11, 5]')\n",
    "    plt.xlabel('Variable ID')\n",
    "    plt.ylabel('R**2')\n",
    "    scatter(x,y,c='r',s=200,alpha=0.5,label = label1)\n",
    "    plt.legend(loc='lower left',fontsize=20)\n",
    "    \n",
    "    fig2 = plt.figure(figsize(6,3), dpi = 80)\n",
    "    #plt.xlim(0,35)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.title('RANKED R**2 & PRICE OR DEG 2 TRANSFO OF SELECTED 9 best features')\n",
    "    plt.xlabel('Distribution')\n",
    "    plt.ylabel('R**2')\n",
    "    x1 = np.linspace(0,len(x),num=len(x))\n",
    "    scatter(x1,y,c='r',s=200,alpha=0.5,label = label1)\n",
    "    plt.legend(loc='upper right',fontsize=20)\n",
    "    \"\"\"\"\"\"\n",
    "    return orderedArrayV,k,selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureSelectionFR(arX,arY,k):\n",
    "    #Univariate linear regression tests.\n",
    "    #Quick linear model for testing the effect of a single regressor, sequentially for many regressors.\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.feature_selection import f_regression\n",
    "    #SELECTING k BEST CORING FEATURES\n",
    "    selectedFeatures = []\n",
    "    X_new = SelectKBest(f_regression, k).fit_transform(arX, arY)\n",
    "    clf = SelectKBest(f_regression, k).fit(arX, arY)\n",
    "    selFea = clf.get_support()\n",
    "    for i in range(len(selFea)):\n",
    "        if selFea[i] == True:\n",
    "            selectedFeatures.append(i)\n",
    "    #print selectedFeatures\n",
    "    #print 'arX.shape = ',arX.shape\n",
    "    #print 'X_new.shape = ',X_new.shape\n",
    "    return X_new, k,selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureSelectionMIR(arX,arY,k):\n",
    "    #NOT WORKING\n",
    "    #from sklearn.feature_selection import mutual_info_regression\n",
    "    import sklearn.feature_selection\n",
    "    selectedFeatures = []\n",
    "    #MAKE k = n_neighbors=3\n",
    "    X_new = sklearn.feature_selection.mutual_info_regression(X, y, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)\n",
    "    print 'arX.shape = ',arX.shape\n",
    "    print 'X_new.shape = ',X_new.shape\n",
    "    return X_new, k,selectedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureSelectionRFE(X,y,estimator,n_features_to_select):\n",
    "    #Feature ranking with recursive feature elimination\n",
    "    from sklearn.feature_selection import RFE\n",
    "    #RFE(estimator, n_features_to_select=None, step=1, verbose=0)#if none : 50% of features selected\n",
    "    #estimator = SVR(kernel=\"linear\")\n",
    "    #selector = RFE(estimator, 5, step=1)\n",
    "    selectedFeatures = []\n",
    "    selector = RFE(estimator,n_features_to_select, step=1)\n",
    "    selector = selector.fit(X, y) #fitting RFE then estimator model on selected features\n",
    "    selFea = selector.support_\n",
    "    for i in range(len(selFea)):\n",
    "        if selFea[i] == True:\n",
    "            selectedFeatures.append(i)\n",
    "    #print selectedFeatures\n",
    "    #selector.support_ #array of shape n_features = mask or integer index of selected features\n",
    "    #selector.ranking_ #array of shape n_features feature ranking; ranking_[i] = position of ith feature; best ranking = 1\n",
    "    #selector.predict(X,y)\n",
    "    #selector.score(X,y)\n",
    "    new_X = selector.transform(X)#reduces X to selected features\n",
    "    #selector.fit_transform(X,y)  #fit_transform(X, y=None, **fit_params) \n",
    "    #Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.\n",
    "    return new_X, n_features_to_select,selectedFeatures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def featureSelectionSFM(X,y,estimator,k,threshold):\n",
    "    #Select from model Meta-transformer for selecting features based on importance weights.\n",
    "    #SFM selects a specific nb of best features dependong on threshold which is NOT equal to nb of selected features\n",
    "    #Ici, threshold = nombre total k de variables considérées, utiliser un grand seuil (>1000) si utilisation du prix, petit si log(prix)\n",
    "    #sfm = SelectFromModel(estimator, threshold='median') = 50% of dim; threshold = 1 & 0.1 & 10 7 100 = most dim\n",
    "    from sklearn.feature_selection import SelectFromModel \n",
    "    sfm = SelectFromModel(estimator, threshold)\n",
    "    selectedFeatures = []\n",
    "    #sfm = SelectFromModel(estimator, threshold=k)\n",
    "    sfm.fit(X, y)\n",
    "    n_features = sfm.transform(X).shape[1]\n",
    "    new_X = sfm.transform(X) # Reduce X to the selected features\n",
    "    selFea = sfm.get_support()\n",
    "    for i in range(len(selFea)):\n",
    "        if selFea[i] == True:\n",
    "            selectedFeatures.append(i)\n",
    "    #print selectedFeatures\n",
    "    # Reset the threshold till the number of features equals two.\n",
    "    # Note that the attribute can be set directly instead of repeatedly\n",
    "    # fitting the metatransformer.\n",
    "    #while n_features > 2:\n",
    "        #sfm.threshold += 0.1\n",
    "        #X_transform = sfm.transform(X)\n",
    "        #n_features = X_transform.shape[1]\n",
    "    return new_X,n_features,selectedFeatures,threshold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix d'une méthode de sélection de features: retourne un tableau des meilleures features et k: nb de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bestFeatureMethod(method,X,y,estimator,k):\n",
    "    if method == 'corCoef' :\n",
    "        return featureSelectionCorCoef(X,y,k)\n",
    "    elif method == 'FR' :\n",
    "        return featureSelectionFR(X,y,k)\n",
    "    elif method == 'MIR' :\n",
    "        return featureSelectionMIR(X,y,k) #NOT WORKING\n",
    "    elif method == 'RFE' :\n",
    "        kn_features_to_select = k\n",
    "        return featureSelectionRFE(X,y,estimator,kn_features_to_select)\n",
    "        #k = n_features_to_select\n",
    "    elif method == 'SFM' :\n",
    "        threshold = 1500\n",
    "        return featureSelectionSFM(X,y,estimator,k,threshold)\n",
    "    else:\n",
    "        print 'No feature selection method corresponds to method ',method\n",
    "        return 0,0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAS 1: modeles de regression lineaire avec best selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def case1_LR_BestFeatures(colDigitPrice,colDigitCorVar,fit_intercept,model,alpha):\n",
    "    #lR MODEL WITHOUT PARAMETER SELECTION \n",
    "    clf = LR_models(model,colDigitCorVar,colDigitPrice,fit_intercept,alpha)\n",
    "    #print ' Case 1: ',nbInputs,' best selected digit features with LR model = ',model,' and alpha = ',alpha\n",
    "    #print 'clf.coef = ',clf.coef_,' clf.coef_.shape = ',clf.coef_.shape\n",
    "    #print 'clf.get_params() = ',clf.get_params() #inutile\n",
    "    #print 'clf.intercept = {0:1.12}'.format(clf.intercept_)\n",
    "    #print 'clf.score(X,y) R^2 = {0:1.3}'.format(clf.score(colDigitCorVar,colDigitPrice))\n",
    "    if model == 'RidgeCV':\n",
    "        print 'model == RidgeCV clf.alpha estimated = ',clf.alpha_\n",
    "    predictedY = clf.predict(colDigitCorVar)\n",
    "    error = 0\n",
    "    for i in range(dataA.shape[0]):   \n",
    "        error += np.abs(colDigitPrice[i]-predictedY[i])/colDigitPrice[i]\n",
    "    errorA = 100*error/dataA.shape[0]\n",
    "    #print ' error at training = {0:2.7}'.format(errorA),'%'\n",
    "    return clf, errorA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kernelRidgeFn(arX,arY,alpha,degree):\n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "    #NON utilisée\n",
    "    #KernelRidge(alpha, coef0=1, degree, gamma=None, kernel='linear',kernel_params=None)\n",
    "    #clf = KernelRidge(alpha)\n",
    "    coef0 = 1\n",
    "    gamma = None\n",
    "    kernel = 'linear'\n",
    "    kernel_params=None\n",
    "    clf = KernelRidge(alpha, coef0, degree, gamma, kernel,kernel_params)\n",
    "    clf.fit(arX, arY) \n",
    "    predictedY = clf.predict(arX)\n",
    "    error = 0\n",
    "    for i in range(arX.shape[0]):   \n",
    "        error += np.abs(arY[i]-predictedY[i])/arY[i]\n",
    "    errorA = int(100*error/arX.shape[0])\n",
    "    #print ' error at training = {0:2.7}'.format(errorA),'%'\n",
    "    return errorA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation non lineaire par sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def polynFn(arX, degree):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    #PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)\n",
    "    #If interaction_only = true, only interaction features are produced: features that are products of at most degree distinct input features (so not x[1] ** 2, x[0] * x[2] ** 3, etc.).\n",
    "    #fit_transform(X, y=None, **fit_params) = Fits transformer to X and y with optional parameters fit_params and returns a transformed version of X.\n",
    "    #transform(X[, y])\tTransform data to polynomial features\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    #poly.fit_transform(X)\n",
    "    A = poly.fit(arX)\n",
    "    newX = poly.transform(arX)\n",
    "    nbFeaturesPoly = poly.n_output_features_ \n",
    "    return newX,nbFeaturesPoly\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train0 = extraction de matrice x et target price; sélection du modele utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train0(dataA,colDigit,typeModel,degree):\n",
    "    #Sélection des colonnes numériques seulement + colonne 12\n",
    "    #coL2 = col2(dataA)\n",
    "    #coL79 = col79(dataA)\n",
    "    coL12 = col12(dataA)\n",
    "    colDigitArrayP12 = digitArrayPlus12Fn(colDigit,dataA,coL12)\n",
    "    #print 'colDigit = ',colDigit\n",
    "    #TARGET ARRAY\n",
    "    colDigitPrice = arange((1*dataA.shape[0]),dtype='f').reshape(dataA.shape[0],1)\n",
    "    for i in range(dataA.shape[0]):\n",
    "        colDigitPrice[i] = float(dataA[i,-1])  \n",
    "    if typeModel == 'LinearReg_sansFS':\n",
    "        return train_LR_sansFS(colDigitArrayP12,colDigitPrice,colDigit[:-1])\n",
    "    if typeModel == 'LinearReg_avecFS':\n",
    "        return train_LR_avecFS(colDigitArrayP12,colDigitPrice)\n",
    "    elif typeModel == 'NonLinTransfReg_avecFS':\n",
    "        return train_NLTR_avecFS(colDigitArrayP12,colDigitPrice,degree)\n",
    "    elif typeModel == 'SVR':\n",
    "        print 'AT SVR'\n",
    "        colDigitPriceR = np.ravel(colDigitPrice)\n",
    "        return svrFn(colDigitArrayP12,colDigitPriceR)\n",
    "    elif typeModel == 'Other':\n",
    "        print 'Other training model to define'\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parametres communs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelHyperParameters():\n",
    "    alphas = [0.0,1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "    LR_reg_models = ['Ridge','Lasso','ElasticNet','RidgeCV','LassoCV','LassoLarsCV']\n",
    "    FeatureSelectionMethods = ['corCoef','FR','RFE','SFM'] #MIR nor working\n",
    "    return alphas,LR_reg_models,FeatureSelectionMethods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphiques communs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graphiques(nbFeatures,errorA,errorB,alphas,titleA,titleB):\n",
    "    if errorB !=0:\n",
    "        fig = plt.figure(figsize(6,3), dpi = 80)\n",
    "        plt.xlim(0,nbFeatures+1)\n",
    "        plt.ylim(0,int(max(errorB)+5))\n",
    "        #plt.title('ERROR vs Nb of FEATURES BY SELECTION COOR COEF AT ALPHA = 0 & USING LR RIDGE')\n",
    "        plt.title(titleA)\n",
    "        plt.xlabel('NB OF SELECTED FEATURES')\n",
    "        plt.ylabel('% ERROR')\n",
    "        x = np.linspace(1,len(errorB),num=len(errorB))\n",
    "        plt.scatter(x,errorB,c='r',s=200,alpha=0.5,label = '%ERROR')               \n",
    "        plt.legend(loc='upper left',fontsize=10)\n",
    "                  \n",
    "    fig1 = plt.figure(figsize(6,3), dpi = 80)\n",
    "    plt.xlim(0,alphas[-1]+2)\n",
    "    plt.ylim(0,int(max(errorA)+5))\n",
    "    #plt.title('ERROR vs ALPHAS USING BEST FEATURES BY COOR COEF WITH LR RIDGE')\n",
    "    plt.title(titleB)\n",
    "    plt.xlabel('ALPHAS')\n",
    "    plt.ylabel('% ERROR')\n",
    "    plt.scatter(alphas,errorA,c='r',s=200,alpha=0.5,label = '%ERROR')\n",
    "    plt.legend(loc='upper left',fontsize=10)\n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele lineaire sans selection de feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_LR_sansFS(colDigitArrayP12,colDigitPrice,colDigit):\n",
    "    print 'Training avec modele de régression lineaire sans selection de features'\n",
    "    #alphas pour régulation\n",
    "    alphas,LR_reg_models,FeatureSelectionMethods = modelHyperParameters()\n",
    "    fit_intercept = True\n",
    "    l1_ratio=0.5\n",
    "    #ElasticNet(alpha, l1_ratio=0.5, fit_intercept=True, normalize=False,precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None,selection='cyclic')\n",
    "    estimatorL = [Ridge(alphas[0],fit_intercept),Lasso(alphas[0],fit_intercept),ElasticNet(alphas[0],l1_ratio,fit_intercept)]\n",
    "    #SFM selects a specific nb of best features depending on threshold which is NOT equal to nb of selected features\n",
    "    #Case 1: Linear regression and best selected features\n",
    "    clf, error =case1_LR_BestFeatures(colDigitPrice,colDigitArrayP12,fit_intercept,LR_reg_models[0],alphas[0])      \n",
    "\n",
    "    print ' Nb features = ',colDigitArrayP12.shape[1],'Modele lineaire = ',LR_reg_models[0],' alpha a training = ',alphas[0],' erreur = ',error \n",
    "   \n",
    "    #A REFAIRE AVEC VALIDATION SET\n",
    "    clfList2 = []\n",
    "    errorA = []\n",
    "    for alpha in alphas:   \n",
    "        clfFn, error = case1_LR_BestFeatures(colDigitPrice,colDigitArrayP12,fit_intercept,LR_reg_models[0],alpha)\n",
    "        errorA.append(error)\n",
    "        clfList2.append(clfFn)\n",
    "    \n",
    "    minAlpha = 0\n",
    "    deltaError = 0.001\n",
    "    indexFalseminAlpha = False\n",
    "    j = 0\n",
    "    while minAlpha < 1:\n",
    "        for i in range(len(errorA) - 1):\n",
    "            if np.abs(errorA[i] - errorA[i+1]) < deltaError :\n",
    "                break\n",
    "            else:\n",
    "                minAlpha = i\n",
    "        deltaError = deltaError*1.01\n",
    "        j += 1\n",
    "        if j > 200:\n",
    "            print 'Ne peut converger a errorA'\n",
    "            break\n",
    "        \n",
    "    print 'Choix de alpha permettant une erreur minimale'\n",
    "    print 'min(errorA) = ',min(errorA),'%',' argmin(errorA) = ',argmin(errorA)\n",
    "    print ' indice minAlpha = ',minAlpha,' errorA a minAlpha = ',errorA[minAlpha],' alpha a min error = ',alphas[minAlpha]\n",
    "    \n",
    "    titleA = ''\n",
    "    titleB = 'ERROR vs ALPHAS USING BEST FEATURES BY COOR COEF WITH LR RIDGE'\n",
    "    print 'clDigit = ',colDigit\n",
    "    graphiques(colDigitArrayP12.shape[1],errorA,0,alphas,titleA,titleB)\n",
    "    return colDigitArrayP12,colDigit,clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele lineaire avec selection de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_LR_avecFS(colDigitArrayP12,colDigitPrice):\n",
    "    print 'Training avec modele de régression lineaire avec selection de features'\n",
    "    #alphas pour régulation\n",
    "    alphas,LR_reg_models,FeatureSelectionMethods = modelHyperParameters()\n",
    "    fit_intercept = True\n",
    "    l1_ratio=0.5\n",
    "    #ElasticNet(alpha, l1_ratio=0.5, fit_intercept=True, normalize=False,precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None,selection='cyclic')\n",
    "    #alphas = [0.0,1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "    estimatorL = [Ridge(alphas[0],fit_intercept),Lasso(alphas[0],fit_intercept),ElasticNet(alphas[0],l1_ratio,fit_intercept)]\n",
    "    #SFM selects a specific nb of best features depending on threshold which is NOT equal to nb of selected features\n",
    "    #Case 1: Linear regression and best selected features\n",
    "    #Below required for feature selection methods\n",
    "    colDigitPriceR = np.ravel(colDigitPrice)\n",
    "    nbFeatures = colDigitArrayP12.shape[1]\n",
    "    #FeatureSelectionMethods = ['corCoef','FR','RFE','SFM']\n",
    "    FSMethod = FeatureSelectionMethods[3]\n",
    "    errorB = []\n",
    "    clfList = []\n",
    "    SelectedFeaturesList = []\n",
    "    featuresArrayList = []\n",
    "    if FSMethod != 'SFM': \n",
    "        for nFeat in range(1,nbFeatures):\n",
    "            featuresArray, k, selectedFeatures = bestFeatureMethod(FSMethod,colDigitArrayP12,colDigitPriceR,estimatorL[0],nFeat)\n",
    "            SelectedFeaturesList.append((nFeat,selectedFeatures))\n",
    "            featuresArrayList.append((nFeat,featuresArray))\n",
    "            clf, error =case1_LR_BestFeatures(colDigitPrice,featuresArray,fit_intercept,LR_reg_models[0],alphas[0])\n",
    "            errorB.append(float(error))\n",
    "            clfList.append(clf)\n",
    "    else:\n",
    "        nFeat = nbFeatures\n",
    "        featuresArray, k, selectedFeatures,threshold = bestFeatureMethod(FSMethod,colDigitArrayP12,colDigitPriceR,estimatorL[0],nFeat)\n",
    "        SelectedFeaturesList.append((nFeat,selectedFeatures))\n",
    "        featuresArrayList.append((nFeat,featuresArray))\n",
    "        clf, error =case1_LR_BestFeatures(colDigitPrice,featuresArray,fit_intercept,LR_reg_models[0],alphas[0])\n",
    "        errorB.append(float(error))\n",
    "        clfList.append(clf)\n",
    "        #print 'Linear regression model = ',LR_reg_models[0],' nb features = ',nFeat,' FeatureSelectionMethods = ',FeatureSelectionMethods[0]\n",
    "        #print 'estimator = ',estimatorL[0],' alphas = ',alphas[0]\n",
    "        #print ' error =', error\n",
    "    print ' Nb maximal de features = ',nbFeatures,' FeatureSelectionMethods = ',FSMethod,'Modele lineaire = ',LR_reg_models[0],' alpha a training = ',alphas[0] \n",
    "    if FSMethod == 'RFE':\n",
    "        print 'RFE estimator = ',estimatorL[0]\n",
    "    if FSMethod == 'SFM':\n",
    "        print 'SFM threshold = ',threshold,' estimator = ',estimatorL[0]\n",
    "    #TO CHANGE: WORK IN REVERSE FROM MIN TO BACK\n",
    "    print ' Erreur minimale = ',min(errorB),' Nb de features à erreur minimale = ',len(SelectedFeaturesList[argmin(errorB)][1])\n",
    "    if FSMethod == 'SFM':\n",
    "        print ' Selected Features selon SFM = ',SelectedFeaturesList[argmin(errorB)][1]\n",
    "    if FSMethod != 'SFM':\n",
    "        #SELECT errorDim < 0.5 - 0.75 for i nb of variables to select\n",
    "        error0 = errorB[0]\n",
    "        nbSelectedFeatures = 0\n",
    "        errorDim = []\n",
    "        for i in range(1,len(errorB)):\n",
    "            errorDim.append((i+1,float((error0-errorB[i])/(i+1))))\n",
    "        errorDim.sort(key=itemgetter(1),reverse=True)\n",
    "        for i in range(len(errorDim)-1,0,-1):\n",
    "            if errorDim[i][1] > 0.4:\n",
    "                nbSelectedFeatures = errorDim[i][0]\n",
    "                break\n",
    "        if nbSelectedFeatures == 0:        \n",
    "            #errorDim.sort(key=itemgetter(1),reverse=True)                \n",
    "            #for i in range(len(errorDim)):\n",
    "            print 'errorDim = ',errorDim            \n",
    "            print 'nbSelectedFeatures non trouvé selon delta erreur par nb de features'\n",
    "            nbSelectedFeatures = argmin(errorB)\n",
    "        print 'Choix du nb de features selon delta erreur par nb de features = ',nbSelectedFeatures,' erreur = ',errorB[nbSelectedFeatures]\n",
    "        print ' Features selon delta erreur par nb de features = ',SelectedFeaturesList[nbSelectedFeatures-1][1]   \n",
    "    \n",
    "    if FSMethod == 'SFM':\n",
    "        nbSelectedFeatures = argmin(errorB)\n",
    "        \n",
    "    #A REFAIRE AVEC VALIDATION SET\n",
    "    errorA = []\n",
    "    clfList2 = []\n",
    "    for alpha in alphas:   \n",
    "        clfFn, error = case1_LR_BestFeatures(colDigitPrice,featuresArrayList[nbSelectedFeatures][1],fit_intercept,LR_reg_models[0],alpha)\n",
    "        errorA.append(error)\n",
    "        clfList2.append(clfFn)\n",
    "    \n",
    "    minAlpha = 0\n",
    "    deltaError = 0.001\n",
    "    indexFalseminAlpha = False\n",
    "    j = 0\n",
    "    while minAlpha < 1:\n",
    "        for i in range(len(errorA) - 1):\n",
    "            if np.abs(errorA[i] - errorA[i+1]) < deltaError :\n",
    "                break\n",
    "            else:\n",
    "                minAlpha = i\n",
    "        deltaError = deltaError*1.01\n",
    "        j += 1\n",
    "        if j > 200:\n",
    "            print 'Ne peut converger a errorA'\n",
    "            break\n",
    "        \n",
    "    print 'Choix de alpha permettant une erreur minimale'\n",
    "    print 'min(errorA) = ',min(errorA),'%',' argmin(errorA) = ',argmin(errorA)\n",
    "    print ' indice minAlpha = ',minAlpha,' errorA a minAlpha = ',errorA[minAlpha],' alpha a min error = ',alphas[minAlpha]\n",
    "    \n",
    "    titleA = 'ERROR vs Nb of FEATURES BY SELECTION '+str(FSMethod)+' AT ALPHA = 0 & USING LR RIDGE'\n",
    "    titleB = 'ERROR vs ALPHAS USING BEST FEATURES BY '+ str(FSMethod)+' WITH LR RIDGE'\n",
    "    if FSMethod == 'SFM':\n",
    "        errorB = 0\n",
    "    graphiques(nbFeatures,errorA,errorB,alphas,titleA,titleB)\n",
    "    return featuresArrayList[nbSelectedFeatures][1],SelectedFeaturesList[nbSelectedFeatures][1],clfList[nbSelectedFeatures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modele lineaire avec transformation non lineaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_NLTR_avecFS(colDigitArrayP12,colDigitPrice,degree):\n",
    "    print 'Training avec transformation non lineaire de degre ',degree,' et modele de régression lineaire avec selection de features'\n",
    "    #DELTA FROM LR\n",
    "    \n",
    "    alphas,LR_reg_models,FeatureSelectionMethods = modelHyperParameters()\n",
    "    fit_intercept = True\n",
    "    l1_ratio=0.5\n",
    "    #ElasticNet(alpha, l1_ratio=0.5, fit_intercept=True, normalize=False,precompute=False, max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None,selection='cyclic')\n",
    "    #alphas = [0.0,1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "    estimatorL = [Ridge(alphas[6],fit_intercept),Lasso(alphas[0],fit_intercept),ElasticNet(alphas[0],l1_ratio,fit_intercept)]\n",
    "    #SFM selects a specific nb of best features depending on threshold which is NOT equal to nb of selected features\n",
    "    #Case 1: Linear regression and best selected features\n",
    "    #Below required for feature selection methods\n",
    "    colDigitPriceR = np.ravel(colDigitPrice)\n",
    "    nbFeatures = colDigitArrayP12.shape[1]\n",
    "    #FeatureSelectionMethods = ['corCoef','FR','RFE','SFM']\n",
    "    FSMethod = FeatureSelectionMethods[0]\n",
    "    errorB = []\n",
    "    clfList = []\n",
    "    SelectedFeaturesList = []\n",
    "    featuresArrayList = []\n",
    "    if FSMethod != 'SFM': \n",
    "        for nFeat in range(1,nbFeatures):\n",
    "            featuresArray, k, selectedFeatures = bestFeatureMethod(FSMethod,colDigitArrayP12,colDigitPriceR,estimatorL[0],nFeat)\n",
    "            SelectedFeaturesList.append((nFeat,selectedFeatures))\n",
    "            featuresArrayList.append((nFeat,featuresArray))  \n",
    "           \n",
    "            featuresDeg, nbFeaturesPoly = polynFn(featuresArray, degree)\n",
    "            \n",
    "            clf, error =case1_LR_BestFeatures(colDigitPrice,featuresDeg,fit_intercept,LR_reg_models[0],alphas[0])\n",
    "            errorB.append(float(error))\n",
    "            clfList.append(clf)\n",
    "    else:\n",
    "        nFeat = nbFeatures\n",
    "        featuresArray, k, selectedFeatures,threshold = bestFeatureMethod(FSMethod,colDigitArrayP12,colDigitPriceR,estimatorL[0],nFeat)\n",
    "        SelectedFeaturesList.append((nFeat,selectedFeatures))\n",
    "        featuresArrayList.append((nFeat,featuresArray))\n",
    " \n",
    "        featuresDeg, nbFeaturesPoly = polynFn(featuresArray, degree)                             \n",
    "                                     \n",
    "        clf, error =case1_LR_BestFeatures(colDigitPrice,featuresDeg,fit_intercept,LR_reg_models[0],alphas[0])\n",
    "        errorB.append(float(error))\n",
    "        clfList.append(clf)\n",
    "        #print 'Linear regression model = ',LR_reg_models[0],' nb features = ',nFeat,' FeatureSelectionMethods = ',FeatureSelectionMethods[0]\n",
    "        #print 'estimator = ',estimatorL[0],' alphas = ',alphas[0]\n",
    "        #print ' error =', error\n",
    "    print ' Nb maximal de features = ',nbFeatures,' FeatureSelectionMethods = ',FSMethod,'Modele lineaire = ',LR_reg_models[0],' alpha a training = ',alphas[0] \n",
    "    print ' nbFeaturesPoly = ',nbFeaturesPoly\n",
    "    if FSMethod == 'RFE':\n",
    "        print 'RFE estimator = ',estimatorL[0]\n",
    "    if FSMethod == 'SFM':\n",
    "        print 'SFM threshold = ',threshold,' estimator = ',estimatorL[0]\n",
    "    #TO CHANGE: WORK IN REVERSE FROM MIN TO BACK\n",
    "    print ' Erreur minimale = ',min(errorB),' Nb de features à erreur minimale = ',len(SelectedFeaturesList[argmin(errorB)][1])\n",
    "    if FSMethod == 'SFM':\n",
    "        print ' Selected Features selon SFM = ',SelectedFeaturesList[argmin(errorB)][1]\n",
    "    if FSMethod != 'SFM':\n",
    "        #SELECT errorDim < 0.5 - 0.75 for i nb of variables to select\n",
    "        error0 = errorB[0]\n",
    "        nbSelectedFeatures = 0\n",
    "        errorDim = []\n",
    "        for i in range(1,len(errorB)):\n",
    "            errorDim.append((i+1,float((error0-errorB[i])/(i+1))))\n",
    "        errorDim.sort(key=itemgetter(1),reverse=True)\n",
    "        for i in range(len(errorDim)-1,0,-1):\n",
    "            if errorDim[i][1] > 0.4:\n",
    "                nbSelectedFeatures = errorDim[i][0]\n",
    "                break\n",
    "        if nbSelectedFeatures == 0:        \n",
    "            #errorDim.sort(key=itemgetter(1),reverse=True)                \n",
    "            #for i in range(len(errorDim)):\n",
    "            print 'errorDim = ',errorDim            \n",
    "            print 'nbSelectedFeatures non trouvé selon delta erreur par nb de features'\n",
    "            nbSelectedFeatures = argmin(errorB)\n",
    "        print 'Choix du nb de features selon delta erreur par nb de features = ',nbSelectedFeatures,' erreur = ',errorB[nbSelectedFeatures]\n",
    "        print ' Features selon delta erreur par nb de features = ',SelectedFeaturesList[nbSelectedFeatures-1][1]   \n",
    "    \n",
    "    if FSMethod == 'SFM':\n",
    "        nbSelectedFeatures = argmin(errorB)\n",
    "        \n",
    "    #A REFAIRE AVEC VALIDATION SET\n",
    "    errorA = []\n",
    "    clfList2 = []\n",
    "    for alpha in alphas:   \n",
    "        clfFn, error = case1_LR_BestFeatures(colDigitPrice,featuresArrayList[nbSelectedFeatures][1],fit_intercept,LR_reg_models[0],alpha)\n",
    "        errorA.append(error)\n",
    "        clfList2.append(clfFn)\n",
    "    \n",
    "    minAlpha = 0\n",
    "    deltaError = 0.001\n",
    "    indexFalseminAlpha = False\n",
    "    j = 0\n",
    "    while minAlpha < 1:\n",
    "        for i in range(len(errorA) - 1):\n",
    "            if np.abs(errorA[i] - errorA[i+1]) < deltaError :\n",
    "                break\n",
    "            else:\n",
    "                minAlpha = i\n",
    "        deltaError = deltaError*1.01\n",
    "        j += 1\n",
    "        if j > 200:\n",
    "            print 'Ne peut converger a errorA'\n",
    "            break\n",
    "        \n",
    "    print 'Choix de alpha permettant une erreur minimale'\n",
    "    print 'min(errorA) = ',min(errorA),'%',' argmin(errorA) = ',argmin(errorA)\n",
    "    print ' indice minAlpha = ',minAlpha,' errorA a minAlpha = ',errorA[minAlpha],' alpha a min error = ',alphas[minAlpha]\n",
    "    \n",
    "    titleA = 'ERROR vs Nb of FEATURES BY SELECTION '+str(FSMethod)+' AT ALPHA = 0 & USING LR RIDGE'\n",
    "    titleB = 'ERROR vs ALPHAS USING BEST FEATURES BY '+ str(FSMethod)+' WITH LR RIDGE'\n",
    "    if FSMethod == 'SFM':\n",
    "        errorB = 0\n",
    "    graphiques(nbFeatures,errorA,errorB,alphas,titleA,titleB)\n",
    "    return featuresArrayList[nbSelectedFeatures][1],SelectedFeaturesList[nbSelectedFeatures][1],clfList[nbSelectedFeatures]\n",
    "        \n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeles svr par sklearn premiers essais peu concluants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def svrFn(arX,y):\n",
    "    from sklearn.svm import SVR\n",
    "    k = arX.shape[1]\n",
    "    selectedFeatures = []\n",
    "    print 'arX.shape = ',arX.shape,' y.shape = ',y.shape \n",
    "    arXS,k,selectedFeatures = featureSelectionCorCoef(arX,y,k)\n",
    "    print arXS.shape\n",
    "    X = arXS[:,:5]\n",
    "    svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "    svr_lin = SVR(kernel='linear', C=1e3)\n",
    "    #svr_poly = SVR(kernel='poly', C=1e3, degree=2)\n",
    "    y_rbf = svr_rbf.fit(X, y).predict(X)\n",
    "    y_lin = svr_lin.fit(X, y).predict(X)\n",
    "    #y_poly = svr_poly.fit(X, y).predict(X)\n",
    "    \n",
    "    error_rbf = 0\n",
    "    error_lin = 0\n",
    "    error_poly = 0\n",
    "    for i in range(X.shape[0]):   \n",
    "        error_rbf += np.abs(y[i]-y_rbf[i])/y[i]\n",
    "        error_lin += np.abs(y[i]-y_lin[i])/y[i]\n",
    "        #error_poly += np.abs(y[i]-y_poly[i])/y[i]\n",
    "    error_rbfA = int(100*error_rbf/X.shape[0])\n",
    "    #error_rbfA = 0 # = 31\n",
    "    error_linA = 0\n",
    "    error_polyA = 0\n",
    "    error_linA = int(100*error_lin/X.shape[0])\n",
    "    #error_polyA = int(100*error_poly/X.shape[0])\n",
    "    #print ' error at training = {0:2.7}'.format(errorA),'%'\n",
    "    return error_rbfA,error_linA,error_polyA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "\n",
      "\n",
      "[1, 4, 12, 17, 18, 19, 20, 34, 36, 37, 38, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 61, 62, 66, 67, 68, 69, 70, 71, 75, 76, 77, 80] \n",
      "\n",
      "\n",
      "Training avec modele de régression lineaire avec selection de features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['pylab']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Nb maximal de features =  34  FeatureSelectionMethods =  SFM Modele lineaire =  Ridge  alpha a training =  0.0\n",
      "SFM threshold =  1500  estimator =  Ridge(alpha=0.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      " Erreur minimale =  12.7859727701  Nb de features à erreur minimale =  16\n",
      " Selected Features selon SFM =  [2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 33]\n",
      "Ne peut converger a errorA\n",
      "Choix de alpha permettant une erreur minimale\n",
      "min(errorA) =  [ 12.68401843] %  argmin(errorA) =  10\n",
      " indice minAlpha =  0  errorA a minAlpha =  [ 12.78597277]  alpha a min error =  0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAADhCAYAAAAeVhjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpH7/8vS1s2OFhD6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a6e57f490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pylab\n",
    "import csv\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge, Lasso, RidgeCV, ElasticNet, LassoCV, LassoLarsCV\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from operator import itemgetter\n",
    "import nltk\n",
    "trainingModel = ['LinearReg_sansFS','LinearReg_avecFS','NonLinTransfReg_avecFS','SVR','Other']\n",
    "dataA, headings = dataInput(\"train_set.csv\")\n",
    "headindsDigit = []\n",
    "colDigit = colDigitFn(dataA)\n",
    "print '\\n\\n', colDigit, '\\n\\n'\n",
    "for col in colDigit:\n",
    "    headindsDigit.append(headings[0][col])\n",
    "#print 'headings = ',headings\n",
    "degree = 2\n",
    "#error_rbfA,error_linA,error_polyA = train0(dataA,colDigit,trainingModel[3],degree)\n",
    "#print ' error_rbfA = ',error_rbfA,' error_linA = ',error_linA,'error_polyA = ',error_polyA\n",
    "bestFeatures,SelectedFeatures,clf = train0(dataA,colDigit,trainingModel[1],degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
